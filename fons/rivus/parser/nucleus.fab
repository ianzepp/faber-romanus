# Parser Nucleus - Core State and Navigation Primitives
#
# The Parser genus maintains all state for recursive descent parsing:
# - Token stream and current position
# - Comment accumulator for AST attachment
# - Error accumulator for diagnostics
# - Unique ID generator for synthetic bindings
#
# INVARIANTS:
# - Token stream always ends with Finis token
# - Position never advances past Finis
# - Never throws - all errors collected in errores
# - Comments collected and attached to next AST node
#
# LATIN VOCABULARY:
# - nucleus = core/kernel
# - symbola = tokens
# - index = current position
# - specta = peek (look at)
# - procede = advance (go forward)
# - proba = check (test)
# - congruet = match (agree with)
# - expecta = expect (wait for)
# - renuncia = report (announce back)
# - synchrona = synchronize
# - notae = comments (marks/notes)

ex "../ast/lexema" importa Symbolum, SymbolumGenus
ex "../ast/radix" importa Nota, NotaGenus
ex "../ast/positio" importa Locus
ex "./errores" importa ParserError, ParserErrorCodice, error
ex "../lexicon/verba" importa estVerbumSententiae, estVerbumGeneris

# Parser state machine
#
# Maintains token stream position, accumulated errors, and pending comments.
# All parsing methods operate on this shared state.
@ publicum
genus Parser {
    lista<Symbolum> symbola       # Token stream from lexer
    numerus index                 # Current position in token stream
    numerus idUnicum              # Counter for unique ID generation
    lista<ParserError> errores    # Accumulated parse errors
    lista<Nota> notaePendentes    # Comments awaiting attachment

    # =========================================================================
    # Unique ID Generation
    # For synthetic bindings (e.g., anonymous cura blocks)
    # =========================================================================

    # Generate unique identifier for synthetic bindings
    # Returns: _prefix_N where N is incremented each call
    @ publica
    functio generaId(textus prae) -> textus {
        fixum id = scriptum("_ยง_ยง", prae, ego.idUnicum)
        ego.idUnicum += 1
        redde id
    }

    # =========================================================================
    # Comment Collection
    # Comments are collected during parsing and attached to AST nodes
    # =========================================================================

    # Convert a comment token to a Nota AST node
    @ publica
    functio symbolumAdNotam(Symbolum s) -> Nota {
        # Determine comment type from token species
        varia notaGenus = NotaGenus.Linea
        si s.species === SymbolumGenus.NotaMassa {
            notaGenus = NotaGenus.Massa
        } sin s.species === SymbolumGenus.NotaDocens {
            notaGenus = NotaGenus.Docens
        }

        redde {
            species: notaGenus,
            valor: s.valor,
            locus: s.locus
        } qua Nota
    }

    # Consume all pending comment tokens into buffer
    # Called before parsing statements/expressions to collect leading comments
    @ publica
    functio colligeNotas() -> vacuum {
        # Keep consuming while current token is a comment
        dum ego.index < ego.symbola.longitudo() {
            fixum s = ego.symbola[ego.index]

            # Check if this is a comment token
            si s.species !== SymbolumGenus.NotaLinea et s.species !== SymbolumGenus.NotaMassa et s.species !== SymbolumGenus.NotaDocens {
                rumpe
            }

            # Convert and buffer the comment
            ego.notaePendentes.adde(ego.symbolumAdNotam(s))
            ego.index += 1
        }
    }

    # Consume pending comments buffer and return them
    # Called when creating AST node to attach as leading comments
    @ publica
    functio consumeNotas() -> lista<Nota>? {
        si ego.notaePendentes.longitudo() === 0 {
            redde nihil
        }

        # Take the pending list and replace with empty
        fixum notae = ego.notaePendentes
        ego.notaePendentes = []
        redde notae
    }

    # Check for trailing comment on same line after current position
    # Returns comment if found on same line as node, nil otherwise
    @ publica
    functio colligeNotamTrahentem(numerus lineaNodi) -> lista<Nota>? {
        si ego.index >= ego.symbola.longitudo() {
            redde nihil
        }

        fixum s = ego.symbola[ego.index]

        # Check if comment token on same line
        fixum estNota = s.species === SymbolumGenus.NotaLinea aut s.species === SymbolumGenus.NotaMassa aut s.species === SymbolumGenus.NotaDocens

        si estNota et s.locus.linea === lineaNodi {
            ego.index += 1
            redde [ego.symbolumAdNotam(s)]
        }

        redde nihil
    }

    # =========================================================================
    # Token Navigation
    # Core primitives: specta (peek), procede (advance), estFinis (at end?)
    # =========================================================================

    # Look ahead at token without consuming, skipping comment tokens
    # distantia = lookahead offset (0 = current, 1 = next, etc.)
    # Returns Finis token if offset goes beyond stream end
    @ publica
    functio specta(numerus distantia) -> Symbolum {
        # Start from current position
        varia pos = ego.index
        varia skipped = 0

        # Skip initial comment tokens
        dum pos < ego.symbola.longitudo() {
            fixum s = ego.symbola[pos]
            si s.species !== SymbolumGenus.NotaLinea et s.species !== SymbolumGenus.NotaMassa et s.species !== SymbolumGenus.NotaDocens {
                rumpe
            }
            pos += 1
        }

        # Skip 'distantia' non-comment tokens
        dum skipped < distantia et pos < ego.symbola.longitudo() {
            pos += 1

            # Skip any comments after advancing
            dum pos < ego.symbola.longitudo() {
                fixum s = ego.symbola[pos]
                si s.species !== SymbolumGenus.NotaLinea et s.species !== SymbolumGenus.NotaMassa et s.species !== SymbolumGenus.NotaDocens {
                    rumpe
                }
                pos += 1
            }

            skipped += 1
        }

        # Return token at position, or last token (Finis) if past end
        si pos < ego.symbola.longitudo() {
            redde ego.symbola[pos]
        }
        
        redde ego.symbola.ultimus()
    }

    # Check if at end of token stream (current token is Finis)
    @ publica
    functio estFinis() -> bivalens {
        redde ego.specta(0).species === SymbolumGenus.Finis
    }

    # Get the previous token (the one most recently consumed)
    # WHY: After congruet() matches and advances, we often need the matched token's
    #      position or value. This avoids needing specta(-1).
    # EDGE: Returns first token if called before any advance (index=0)
    @ publica
    functio praevius() -> Symbolum {
        si ego.index > 0 {
            redde ego.symbola[ego.index - 1]
        }
        
        redde ego.symbola.primus()
    }

    # Get the source position of the current token
    # WHY: Almost every parse function starts with `fixum locus = p.locusActualis()`
    #      This helper reduces boilerplate and clarifies intent.
    @ publica
    functio locusActualis() -> Locus {
        redde ego.specta(0).locus
    }

    # Consume and return current token, collecting comments first
    # Never advances past Finis token
    @ publica
    functio procede() -> Symbolum {
        # Collect any comment tokens first
        ego.colligeNotas()

        # Don't advance past end
        si ego.estFinis() {
            redde ego.symbola[ego.index]
        }

        # Return current and advance
        fixum s = ego.symbola[ego.index]
        ego.index += 1
        redde s
    }

    # =========================================================================
    # Token Predicates
    # proba = check without consuming, congruet = check and consume
    # =========================================================================

    # Check if current token matches given type without consuming
    @ publica
    functio proba(SymbolumGenus species) -> bivalens {
        redde ego.specta(0).species === species
    }

    # Check if current token is a specific keyword without consuming
    # Keywords are stored in token.verbum field
    @ publica
    functio probaVerbum(textus verbum) -> bivalens {
        fixum s = ego.specta(0)
        redde s.species === SymbolumGenus.Verbum et s.verbum === verbum        
    }

    # Match and consume token if type matches
    # Returns true if matched and consumed, false otherwise
    @ publica
    functio congruet(SymbolumGenus species) -> bivalens {
        si ego.proba(species) {
            ego.procede()
            redde verum
        }
        redde falsum
    }

    # Match and consume token if keyword matches
    # Returns true if matched and consumed, false otherwise
    @ publica
    functio congruetVerbum(textus verbum) -> bivalens {
        si ego.probaVerbum(verbum) {
            ego.procede()
            redde verum
        }
        redde falsum
    }

    # Match any of several token types, consuming if matched
    # Returns true if any matched, false otherwise
    @ publica
    functio congruetAliquod(lista<SymbolumGenus> species) -> bivalens {
        ex species pro s {
            si ego.proba(s) {
                ego.procede()
                redde verum
            }
        }
        redde falsum
    }

    # =========================================================================
    # Error Handling
    # renuncia = report error, expecta = require token or error
    # =========================================================================

    # Report error at current position
    # contextus = optional additional context (e.g., "got 'x'")
    @ publica
    functio renuncia(ParserErrorCodice codice, si textus contextus) -> vacuum {
        fixum s = ego.specta(0)
        fixum err = error(codice, s.locus, contextus)
        ego.errores.adde(err)
    }

    # Expect specific token type or record error
    # Returns matched token if found, synthetic token after advancing if not
    # Advances past unexpected token to prevent infinite loops
    @ publica
    functio expecta(SymbolumGenus species, ParserErrorCodice codice) -> Symbolum {
        si ego.proba(species) {
            redde ego.procede()
        }

        # Record error with context
        fixum s = ego.specta(0)
        ego.renuncia(codice, scriptum("got 'ยง'", s.valor))

        # Advance past unexpected token (unless at end)
        si non ego.estFinis() {
            ego.procede()
        }

        # Return synthetic token with expected type but actual position
        redde {
            species: species,
            valor: "",
            locus: s.locus,
            verbum: nihil
        } qua Symbolum
    }

    # Expect specific keyword or record error
    # Returns matched token if found, synthetic token after advancing if not
    @ publica
    functio expectaVerbum(textus verbum, ParserErrorCodice codice) -> Symbolum {
        si ego.probaVerbum(verbum) {
            redde ego.procede()
        }

        # Record error with context
        fixum s = ego.specta(0)
        ego.renuncia(codice, scriptum("got 'ยง'", s.valor))

        # Advance past unexpected token
        si non ego.estFinis() {
            ego.procede()
        }

        # Return synthetic keyword token
        redde {
            species: SymbolumGenus.Verbum,
            valor: verbum,
            locus: s.locus,
            verbum: verbum
        } qua Symbolum
    }

    # =========================================================================
    # Error Recovery
    # synchrona = skip to next statement boundary after error
    # =========================================================================

    # Skip tokens until reaching a statement boundary keyword
    # Called after catching parse error to resume at known-good state
    #
    # WHY: Uses estVerbumSententiae from lexicon/verba.fab as single source
    #      of truth for statement-starting keywords. This prevents drift
    #      between the grammar and error recovery.
    @ publica
    functio synchrona() -> vacuum {
        # Skip current problematic token
        ego.procede()

        # Keep advancing until we hit a statement-starting keyword
        dum non ego.estFinis() {
            fixum s = ego.specta(0)
            si s.species === SymbolumGenus.Verbum et estVerbumSententiae(s.verbum) {
                redde
            }
            ego.procede()
        }
    }

    # Synchronize within genus body (for field/method recovery)
    # Looks for field types, method declarations, or closing brace
    #
    # WHY: Uses estVerbumGeneris from lexicon/verba.fab as single source
    #      of truth for genus member boundaries.
    @ publica
    functio synchronaGenusMembrum() -> vacuum {
        ego.procede()

        dum non ego.estFinis() {
            # Stop at closing brace (end of genus)
            si ego.proba(SymbolumGenus.UncusDex) {
                redde
            }

            # Stop at member-starting keywords
            fixum s = ego.specta(0)
            si s.species === SymbolumGenus.Verbum et estVerbumGeneris(s.verbum) {
                redde
            }

            ego.procede()
        }
    }

    # =========================================================================
    # Type Helpers
    # Predicates for type-first syntax disambiguation
    # =========================================================================

    # Check if token is a builtin type name
    # Used to distinguish "fixum textus nomen" from "fixum nomen"
    @ publica
    functio estTypusNomen(Symbolum s) -> bivalens {
        si s.species !== SymbolumGenus.Nomen reddit falsum

        # Check against builtin type names
        # TODO: This should use a proper type registry
        elige s.valor {
            casu "textus" reddit verum
            casu "numerus" reddit verum
            casu "fractus" reddit verum
            casu "decimus" reddit verum
            casu "magnus" reddit verum
            casu "bivalens" reddit verum
            casu "nihil" reddit verum
            casu "vacuum" reddit verum
            casu "numquam" reddit verum
            casu "ignotum" reddit verum
            casu "octeti" reddit verum
            casu "objectum" reddit verum
            casu "lista" reddit verum
            casu "tabula" reddit verum
            casu "copia" reddit verum
            casu "promissum" reddit verum
            casu "cursor" reddit verum
            casu "unio" reddit verum
            ceterum reddit falsum
        }
    }

    # Check if token is a preposition used in parameters
    # de = borrowed/read-only, in = mutable borrow, ex = source
    @ publica
    functio estPraepositio(Symbolum s) -> bivalens {
        si s.species !== SymbolumGenus.Verbum reddit falsum

        elige s.verbum {
            casu "de" reddit verum
            casu "in" reddit verum
            casu "ex" reddit verum
            ceterum reddit falsum
        }
    }

    # Check if token is an assignment operator
    # Includes = and compound assignments (+=, -=, *=, /=, %=, &=, |=)
    @ publica
    functio estAssignatioSignum(Symbolum s) -> bivalens {
        # For now, only simple assignment is supported
        redde s.species === SymbolumGenus.Aequum
    }
}

# Create a new parser for the given token stream
@ publica
functio novumParser(lista<Symbolum> symbola) -> Parser {
    redde {
        symbola: symbola,
        index: 0,
        idUnicum: 0,
        errores: [],
        notaePendentes: []
    } qua Parser
}
